<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>TosakaUCW</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="TosakaUCW"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="TosakaUCW"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="TosakaUCW"><meta property="og:url" content="https://tosakaucw.github.io/"><meta property="og:site_name" content="TosakaUCW"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://tosakaucw.github.io/img/og_image.png"><meta property="article:author" content="TosakaUCW"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://tosakaucw.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://tosakaucw.github.io"},"headline":"TosakaUCW","image":["https://tosakaucw.github.io/img/og_image.png"],"author":{"@type":"Person","name":"TosakaUCW"},"publisher":{"@type":"Organization","name":"TosakaUCW","logo":{"@type":"ImageObject","url":"https://tosakaucw.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Fira+Code&amp;family=Microsoft+Yahei:wght@400;700"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="TosakaUCW" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a><a class="navbar-item" href="/links">Links</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/TosakaUCW"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-07-04T08:56:39.000Z" title="2024-07-04T08:56:39.000Z">2024-07-04</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-07-04T18:12:05.680Z" title="2024-07-04T18:12:05.680Z">2024-07-05</time></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/360-gs-paper-%E7%BB%86%E8%AF%BB/">360-GS Paper 细读</a></p><div class="content"><h2 id="Paper"><a href="#Paper" class="headerlink" title="Paper"></a>Paper</h2><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><blockquote>
<p>3D 高斯分布 (3D-GS) 最近因实时和照片级逼真的渲染而备受关注。该技术通常以透视图像作为输入，并通过将一组 3D 椭圆高斯分布分布到图像平面上来优化它们，从而产生 2D 高斯分布。然而，将 3D-GS 应用于全景输入对于使用 2D 高斯分布有效地对 360◦ 图像球面投影进行建模提出了挑战。在实际应用中，输入全景图通常很稀疏，导致 3D 高斯分布的初始化不可靠，从而导致 3D-GS 质量下降。此外，由于无纹理平面（例如墙壁和地板）的几何形状约束不足，3D-GS 难以用椭圆高斯分布对这些平坦区域进行建模，导致新视图中出现明显的漂浮物。为了解决这些问题，我们提出了 360-GS，这是一种针对有限全景输入集的新型 360◦ 高斯投影。360-GS 不是将 3D 高斯直接投影到球面上，而是将它们投影到单位球面的切平面上，然后将它们映射到球面投影上。这种调整使得能够使用高斯表示投影。我们通过利用全景图中的布局先验来指导 360-GS 的优化，这些先验易于获取且包含有关室内场景的强大结构信息。我们的实验结果表明，360-GS 允许全景渲染，并且在新型视图合成中以更少的伪影优于最先进的方法，从而在室内场景中提供沉浸式漫游。</p>
</blockquote>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><blockquote>
<p>随着消费级 360◦ 相机的普及，从一组全景图像中合成新颖的视图已成为计算机图形学和视觉应用（包括虚拟现实和增强现实 (VR&#x2F;AR)）的核心组件之一。最近，神经辐射场 (NeRF) [Barron et al. 2021a; Mildenhall et al. 2020] 因其能够产生照片般逼真的渲染而备受关注，并成为一种广泛使用的合成新颖视图的技术。尽管付出了巨大的努力，但 NeRF 沿射线采样密集点来渲染每个单个像素，这对于实时渲染来说是一个挑战。最近，基于点的表示 3D 高斯分层 (3D-GS) [Kerbl et al. 2023] 已成为一种替代表示，它实现了实时速度，并且渲染质量与基于 NeRF 的方法相当。这种有前途的技术使我们能够实时漫游室内房间，它具有许多实际应用，例如自由视点导航、房屋参观和虚拟现实游戏。</p>
<p>然而，3D-GS 主要关注 perspective images。当给定一组 indoor panorama 时，使用 3D-GS 合成新视图会遇到几个挑战。首先，将 3D 高斯分布到全景图像上会产生空间失真，而将 2D 高斯分布到透视投影的图像平面上则无法对其进行建模。因此，无法直接用全景图像优化 3D 高斯。其次，收集场景的密集全景图通常既昂贵又耗时 [Guangcong et al. 2023]。在典型的图像收集过程中，360◦ 相机通常放置在房间的中心或有限的一组位置，从而导致输入稀疏。这种输入的稀缺性显著加剧了从 2D 图像学习 3D 结构的固有模糊性，从而导致渲染效果不令人满意 [Xiong et al. 2023; Zhu et al. 2023]。虽然许多工作试图通过利用深度监督 [Deng et al. 2021; Zhu et al. 2023] 和跨视图语义一致性 [Jain et al. 2021] 等像素级信息来解决少镜头任务，但全景图中的场景级结构信息仍未得到充分利用。第三，室内场景通常包含许多无纹理和平坦的区域，例如墙壁、地板、桌子和天花板，这些区域不足以找到跨视图对应关系。即使 3D-GS 可以很好地拟合训练像素，这些平面的几何形状也不准确，导致在新视图中平面上方出现漂浮物。先前的研究已经通过几何正则化解决了这个问题 [Chen et al. 2022; Deng et al. 2021]，但大多数都是建立在 NeRF 之上的。</p>
<p>为了应对上述挑战，我们提出了 360-GS，这是一种专为稀疏全景图像设计的新型布局引导 3D 高斯溅射管道。该方法实现了实时全景渲染，同时提供了高质量的新颖视图，显着减少了漂浮物等不良伪影，如图 1 所示。 令人印象深刻的性能归功于 360-GS 的两个核心组件：360◦ 高斯溅射和房间布局先验的结合。 360◦ 高斯溅射旨在将 3D 高斯溅射到全景输入的单位球面上。 我们发现空间扭曲的投影很难用高斯建模。 因此，360◦ 高斯溅射算法将溅射分解为两个步骤：将 3D 高斯投影到切平面上，然后将它们映射到球面。 分解避免了投影的​​复杂表示，同时保持了实时性能。</p>
<p>我们通过引入房间布局先验进一步解决了由于少样本输入和无纹理平面导致的约束不足问题。全景图具有完整的视野，因此它本身包含比透视图更丰富的全局结构信息，可以利用这些信息进行更多正则化。房间布局是室内场景中最常见且最容易获得的结构信息。从房间布局中，我们可以得出一个高质量的点云来初始化 3D 高斯。由于房间布局描述了具有平坦墙壁、地板和天花板的场景，我们进一步对这些区域中 3D 高斯的位置施加了约束。布局引导的初始化和正则化有助于生成平面并减少新视图中不必要的漂浮物。在真实数据集上进行的实验证明了我们方法的优越性和有效性。</p>
<p>综上所述，我们论文的主要贡献如下：</p>
<ul>
<li>我们提出了 360-GS，这是一种专为稀疏全景图像设计的布局引导式 3D 高斯溅射管道，可使用我们新颖的 360◦ 高斯溅射算法进行实时全景渲染。</li>
<li>我们从房间布局先验中推导出一种高质量点云生成方法，用于初始化 3D 高斯，以提高少样本新视图合成的性能。</li>
<li>我们在 3D 高斯上引入了布局引导正则化，以减少由约束不足的区域引起的浮动。</li>
</ul>
</blockquote>
<h3 id="RELATED-WORK"><a href="#RELATED-WORK" class="headerlink" title="RELATED WORK"></a>RELATED WORK</h3><h4 id="Novel-view-synthesis"><a href="#Novel-view-synthesis" class="headerlink" title="Novel view synthesis"></a>Novel view synthesis</h4><blockquote>
<p>给定一组密集的校准图像，新视图合成任务旨在从看不见的视点生成 3D 场景的照片般逼真的图像。为了提高重建的 3D 场景和新视图的质量，一些研究利用显式表示，例如分层表示 [Shade et al. 1998; Shih et al. 2020]、体素 [Sitzmann et al. 2018]、网格 [Jack et al. 2018] 和点云 [Qi et al. 2016; Wiles et al. 2019]。最近，人们对体积表示的使用越来越感兴趣。神经辐射场 (NeRF) [Mildenhall et al. 2020] 使用隐式神经网络将场景表示为密度和颜色的连续体积函数。然后使用体积渲染来生成新视图。 Mip-NeRF 360 [Barron et al . 2021b] 扩展了 NeRF 以解决混叠问题并对无界场景进行建模。尽管 NeRF 具有强大的神经隐式表示，但它需要大量时间进行训练和渲染，这对实时应用构成了挑战。最近的研究致力于加快渲染速度 [Müller et al . 2022; Reiser et al. 2021; Sun et al. 2021; Yu et al . 2021]。同时，另一项工作采用基于点的表示和渲染。3D-GS [Kerbl et al. 2023] 使用显式 3D 高斯对场景进行建模，并使用 splatting 技术高效地渲染 2D 图像，将照片般逼真的渲染质量提升到实时水平。虽然现有的新型视图合成方法主要集中于透视图像，但最近的研究已经针对全景输入进行了调整。OmniNeRF [Gu et al . 2022] 将 NeRF 的针孔相机模型扩展为鱼眼投影模型，并使用球面采样来提高渲染质量。360Roam [Huang et al. 2022] 是第一个从全景图像序列构建全向神经辐射场的。360FusionNeRF [Kulkarni et al. 2022] 引入了语义一致性损失以强制全景图中的 3D 空间一致性。相比之下，最近基于 3D 高斯溅射的研究几乎不将全景图视为输入。据我们所知，我们是第一个将 3D-GS 扩展到全景图合成的人。</p>
</blockquote>
<h4 id="Layout-priors-in-panoramas"><a href="#Layout-priors-in-panoramas" class="headerlink" title="Layout priors in panoramas"></a>Layout priors in panoramas</h4><blockquote>
<p>全景房间布局估计在室内场景理解中起着至关重要的作用，并已得到广泛研究 [Jiang et al . 2022; Pintore et al. 2020; Shen et al . 2023a,b; Su et al . 2022; Sun et al . 2019]。其中，Horizo​​nNet [Sun et al . 2019] 引入了一个深度学习网络和后处理技术，可以恢复复杂的房间布局，即使模型输出中的角落被遮挡。这种估计的全景房间布局已在计算机视觉问题中得到广泛探索，包括室内导航 [Mirowski et al . 2016] 和场景重建 [Izadinia et al . 2016]。在新颖视图合成任务中，Xu et al. [2021] 利用从参考全景图中估计的房间布局并提取高级特征作为目标视图的指导，证明了布局先验的有效性。然而，由于 3D 高斯缺乏神经组件，因此房间布局的神经信息在 3D 高斯中未得到充分利用。与此方法不同，我们通过显式初始化和 3D 高斯的几何约束来利用房间布局先验。</p>
</blockquote>
<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><blockquote>
<p>我们提出了 360-GS，这是一种旨在优化 3D 高斯并促进全景渲染的管道。图 2 显示了我们的 360-GS 的概览。我们确定了将全景图适配到 3D-GS 的挑战（第 3.1 节），并提出了 360◦ 高斯拼合作为解决方案。360-GS 进一步设计了布局引导的初始化和正则化，以充分利用全景输入中的房间布局先验。</p>
</blockquote>
<h4 id="Preliminary-and-challenge"><a href="#Preliminary-and-challenge" class="headerlink" title="Preliminary and challenge"></a>Preliminary and challenge</h4><h4 id="360-Gaussian-Splatting"><a href="#360-Gaussian-Splatting" class="headerlink" title="360 Gaussian Splatting"></a>360 Gaussian Splatting</h4><blockquote>
<p>我们的目标是优化一组全景图中的 3D 高斯表示并实现直接全景渲染。考虑到直接表示球面投影的挑战，我们引入了一种新颖的溅射技术，将球面上的溅射分解为两个连续步骤：在单位球面的切平面上溅射并映射到球面。这使我们能够将 3D 高斯投影到 2D 高斯以进行渲染。图 5 显示了我们的 360◦ 高斯溅射的概述。</p>
<p>给定一个以 $\mu$ 为中心、具有协方差矩阵 $\Sigma$ 的 3D 椭圆高斯，我们首先使用仿射观察变换 $V(x)$ 将其转换为相机坐标。观察变换之后是投影变换 $\boldsymbol{t}^{\prime}&#x3D;\varphi\left(\boldsymbol{t},\boldsymbol{\mu}^{\prime}\right)$，它将相机坐标投影到单位球面的切平面。该切平面通过投影点 $\boldsymbol{\mu}^{\prime}$ 并且与以相机坐标原点为中心的单位球面相切。变换公式如下：</p>
<p>$$\mu^{\prime}\left(x-\mu^{\prime}\right)&#x3D;0$$</p>
<p>其中 $\boldsymbol{\mu}^{\prime}$ 是 $V(\boldsymbol{\mu})$ 在单位球面上的投影。因此，投影由以下公式给出：</p>
<p>$$\left(t_0^{\prime}, t_1^{\prime}, t_2^{\prime}\right)^T&#x3D;\varphi\left(\boldsymbol{t}, \boldsymbol{\mu}^{\prime}\right)&#x3D;\boldsymbol{t} \frac{\left(\boldsymbol{\mu}^{\prime}\right)^T \boldsymbol{\mu}^{\prime}}{\left(\boldsymbol{\mu}^{\prime}\right)^T \boldsymbol{t}}$$</p>
<p>按照 Zwicker 等人 [2002] 的观点，我们通过点 $t_k$ 处 $\varphi$ 的泰勒展开式的前两个项来定义局部仿射近似 $\varphi_k\left(\boldsymbol{t}, \boldsymbol{\mu}^{\prime}\right)$:</p>
<p>$$\varphi_k\left(\boldsymbol{t}, \boldsymbol{\mu}^{\prime}\right)&#x3D;\varphi_k\left(\boldsymbol{t}_{\boldsymbol{k}}, \boldsymbol{\mu}^{\prime}\right)+\boldsymbol{J}_k \cdot\left(\boldsymbol{t}-\boldsymbol{t}_k\right)$$</p>
<p>其中 $\boldsymbol{t}_k&#x3D;\left(t_0, t_1, t_2\right)^T&#x3D;V(\boldsymbol{\mu})$ 是相机坐标系中 3D 高斯的中心。雅可比矩阵 $J_k$ 由 $\varphi$ 在点 $t_k$ 处的偏导数给出：</p>
<p>$$<br>\boldsymbol{J}_k&#x3D;\frac{-1}{\left(\mu_0^{\prime} t_0+\mu_1^{\prime} t_1+\mu_2^{\prime} t_2\right)^2}\left[\begin{array}{ccc}<br>\mu_1^{\prime} t_1+\mu_2^{\prime} t_2 &amp; \mu_1^{\prime} t_0 &amp; \mu_2^{\prime} t_0 \<br>\mu_0^{\prime} t_1 &amp; \mu_0^{\prime} t_0+\mu_2^{\prime} t_2 &amp; \mu_2^{\prime} t_1 \<br>\mu_0^{\prime} t_2 &amp; \mu_1^{\prime} t_2 &amp; \mu_0^{\prime} t_0+\mu_1^{\prime} t_1<br>\end{array}\right]$$</p>
<p>这部分 math 懒得搬了，略。。。</p>
<p>通过投影和一对一映射，3D 高斯散布到全景图上。由于映射过程高效，我们的方法保持了实时性能。随后，全景图的像素颜色是通过从前到后对这些分层散布的高斯进行 alpha 混合而得出的，遵循 3D-GS。因此，我们能够直接渲染全景图。</p>
</blockquote>
<h4 id="Layout-prior-for-panoramas"><a href="#Layout-prior-for-panoramas" class="headerlink" title="Layout prior for panoramas"></a>Layout prior for panoramas</h4><blockquote>
<p>在缺乏 3D 信息的稀疏全景图中，3D-GS 难以识别跨视图 3D 对应关系并构建场景的几何形状，导致新视图合成的质量显著下降。在本文中，我们利用房间布局（全景图中的 3D 结构信息的一种形式）来缓解这些问题。将房间布局与 3D 高斯结合起来有三个优点。首先，它包含整个房间的上下文信息和 3D 先验，这些信息在不同视图中是一致的。其次，与深度图和点云表示不同，房间布局以平滑的表面结构描述场景，产生包括墙壁和地板在内的无缝平面 [Jiang et al. 2022]。第三，房间布局易于访问且对场景规模具有鲁棒性。最近的进展极大地推动了布局估计领域的发展，实现了超过 20 帧&#x2F;秒 (FPS) 的帧速率 [Sun et al. 2019]。</p>
<p>假设房间布局符合亚特兰大世界假设 [Pintore et al . 2020]，房间布局由垂直墙壁、水平地板和天花板组成。如图 2 所示，我们使用地板-墙壁边界 𝑩𝑓 ∈ R1×𝑊 和天花板-墙壁边界 𝑩𝑐 ∈ R1×𝑊 来描绘房间布局，其中 𝑩𝑓 和 𝑩𝑐 分别代表每个图像列的天花板和地板边界的纬度。利用已知的摄像机高度，我们将图像中的 2D 边界转换为 3D 位置。随后，我们按照 Pintore 等人 [2019] 的方法恢复地板、天花板和墙壁平面，从而创建一个 3D 边界框作为场景的 3D 房间布局。</p>
</blockquote>
<h4 id="Layout-guided-initialization"><a href="#Layout-guided-initialization" class="headerlink" title="Layout-guided initialization"></a>Layout-guided initialization</h4><blockquote>
<p>先前的研究 [Chen et al. 2023; Kerbl et al. 2023] 已经证明了合理的几何初始化在训练 3D 高斯中的重要性。3D-GS 主张从由运动结构 (SfM) 派生的一组初始稀疏点开始 [Schönberger and Frahm 2016; Schönberger et al. 2016]。然而，Sfm 无法处理稀疏视图输入，因此无法可靠地提供点云初始化 [Sinha et al. 2022]。</p>
<p>鉴于房间布局揭示了场景的整体几何结构，我们将布局点云集成到初始化中。具体而言，我们使用现成的网络估计地板-墙壁边界和天花板-墙壁边界作为每个全景图的布局 [Sun et al. 2019]。为了获得场景的整体布局，我们使用 2D 联合操作合并所有全景图的边界。随后，我们从全局布局构建相应的 3D 边界框，然后通过均匀采样将其转换为点云。为了增强布局中未包含的对象的信息，我们还估计全景图的深度并将深度图转换为点云 [Pintore et al. 2021]。我们合并这些深度点云，然后对其进行下采样以减少点数，同时保持对象的结构。合并的深度点云与具有全局比例因子的布局点云对齐。最后，我们结合布局和深度点云来初始化 3D 高斯。</p>
</blockquote>
<h4 id="Layout-guided-regularization"><a href="#Layout-guided-regularization" class="headerlink" title="Layout-guided regularization"></a>Layout-guided regularization</h4><blockquote>
<p>尽管 3D 高斯最初是用布局引导点云设置的，但全景图中的房间布局先验会遭受灾难性遗忘。如图 6 所示，3D 高斯的参数（例如位置向量 𝝁）在梯度方向上进行了优化。因此，3D-GS 难以保留用布局先验初始化的几何结构，导致表面不平整，并在新视图中出现“漂浮物”。</p>
<p>为了解决这个问题，我们引入了布局引导正则化来强制 3D 高斯保持房间布局的一致性。具体来说，当我们用布局点云初始化 3D 高斯时，我们还会记录它们对应的 3D 布局点的初始位置 𝒖0 和法线 𝒏。我们通过最小化位置移动和法线之间的余弦距离来正则化 3D 高斯的优化。然后，我们汇总所有用布局点云初始化的 3D 高斯的余弦距离。最终的布局引导损失公式为：</p>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-07-03T16:00:53.000Z" title="2024-07-03T16:00:53.000Z">2024-07-04</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-07-04T08:56:55.332Z" title="2024-07-04T08:56:55.332Z">2024-07-04</time></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/neus-paper-%E7%BB%86%E8%AF%BB/">NeuS Paper 细读</a></p><div class="content"><h2 id="Paper"><a href="#Paper" class="headerlink" title="Paper"></a>Paper</h2><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><blockquote>
<p>我们提出了一种新颖的神经表面重建方法，称为NeuS，用于从2D图像输入中高保真重建对象和场景。现有的神经表面重建方法，如DVR [Niemeyer et al., 2020] 和IDR [Yariv et al., 2020]，需要前景掩码作为监督，容易陷入局部最小值，因此在重建具有严重自遮挡或薄结构的对象时存在困难。与此同时，最近的用于新视角合成的神经方法，如NeRF [Mildenhall et al., 2020]及其变体，使用体积渲染来生成具有鲁棒优化特性的神经场景表示，即使对于高度复杂的对象也是如此。然而，从这种学习到的隐式表示中提取高质量的表面非常困难，因为表示中没有足够的表面约束。在NeuS中，我们提出将表面表示为<strong>有符号距离函数（SDF）的 zero-level-set</strong>，并<strong>开发了一种新的体积渲染方法来训练神经SDF表示</strong>。我们观察到，传统的体积渲染方法会导致表面重建固有的几何误差（即偏差），因此我们<strong>提出了一种在一阶近似中无偏差的新公式，从而即使在没有掩码监督的情况下也能实现更精确的表面重建</strong>。DTU数据集和BlendedMVS数据集上的实验表明，NeuS在高质量表面重建方面优于现有最先进的方法，特别是对于具有复杂结构和自遮挡的对象和场景。</p>
</blockquote>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><blockquote>
<p>从多视角图像重建表面是计算机视觉和计算机图形学中的一个基本问题。具有神经隐式表示的 3D 重建最近已成为传统重建方法的一种非常有前途的替代方案 [37, 8, 2]，因为它具有高重建质量和重建传统方法难以实现的复杂物体的潜力，例如 non-Lambertian surfaces 和 thin structures。最近的研究将表面表示为有符号距离函数 (SDF) [49, 52, 17, 23] 或 occupancy [30, 31]。为了训练其神经模型，这些方法使用可微分的表面渲染方法将 3D 对象渲染为图像，并将其与输入图像进行比较以进行监督。例如，IDR [49] 产生了令人印象深刻的重建结果，但它无法重建具有导致突然深度变化的复杂结构的物体。造成这种限制的原因是 IDR 中使用的表面渲染方法仅考虑每条射线的单个表面交点。因此，梯度仅存在于这个单点，对于有效的反向传播来说，这个点过于局部，当图像深度发生突然变化时，优化会陷入不良的局部最小值。此外，需要对象蒙版作为监督，以收敛到有效的表面。如图 1 (a) 顶部所示，由于洞引起的深度剧烈变化，神经网络会错误地将靠近前表面的点预测为蓝色，从而无法找到远处的蓝色表面。图 1 (b) 中的实际测试示例表明，IDR 无法正确重建具有突然深度变化的边缘附近的表面。</p>
<p>最近，NeRF [29] 及其变体探索使用体积渲染方法来学习体积辐射场，以实现新视图合成。这种体积渲染方法沿每条射线采样多个点，并对采样点的颜色进行 α-composition，以生成用于训练目的的输出像素颜色。体积渲染方法的优点是它可以处理突然的深度变化，因为它考虑了射线上的多个点，因此所有采样点（无论是靠近表面还是在远表面上）都会产生用于反向传播的梯度信号。例如，参考图 1 (a) 底部，当发现近表面（黄色）的颜色与输入图像不一致时，体积渲染方法能够训练网络找到远后表面以产生正确的场景表示。然而，由于它旨在用于新视图合成而不是表面重建，因此 NeRF 仅学习体积密度场，从中提取高质量表面很困难。图 1 (b) 显示了通过 NeRF 学习的密度场的水平集表面。虽然表面正确地解释了突然的深度变化，但它在某些平面区域包含明显的噪声。</p>
<p>在本研究中，我们提出了一种新的神经渲染方案，称为 NeuS，用于多视图表面​​重建。NeuS 使用有符号距离函数 (SDF) 进行表面表示，并使用一种新颖的体积渲染方案来学习神经 SDF 表示。具体而言，通过引入由 SDF 诱导的密度分布，我们可以将体积渲染方法应用于学习隐式 SDF 表示，从而兼具两全其美的优势，即使用神经 SDF 模型进行准确的表面表示，并在体积渲染导致的突然深度变化的情况下进行稳健的网络训练。请注意，简单地将标准体积渲染方法应用于与 SDF 相关的密度会导致重建表面出现明显的偏差（即固有的几何误差）。这是一个新的、重要的观察结果，我们将在后面详细阐述。因此，我们提出了一种新颖的体积渲染方案，以确保在 SDF 的一阶近似中进行无偏表面重建。在 DTU 数据集和 BlendedMVS 数据集上的实验表明，即使没有前景蒙版作为监督，NeuS 也能够重建具有严重遮挡和精细结构的复杂 3D 物体和场景。在重建质量方面，它优于最先进的神经场景表示方法，即 IDR [49] 和 NeRF [29]。</p>
</blockquote>
<p>先 diss 了一下 IDR，直接原因是无法重建深度突变的点。接着讲了下 NeRF，用上了体渲染的方法。</p>
<h3 id="Related-Works"><a href="#Related-Works" class="headerlink" title="Related Works"></a>Related Works</h3><blockquote>
<p>Classical Multi-view Surface and Volumetric Reconstruction. 经典的多视图表面​​和体积重建。传统的多视图三维重建方法大致可分为两类：基于点和表面的重建[2,8,9,37]和体积重建[6,3,38]。基于点和表面的重建方法通过利用图像间光度一致性来估计每个像素的深度图[8]，然后将深度图融合为全局密集点云[26,51]。表面重建通常作为后处理，使用筛选泊松曲面重建[16]等方法。重建质量在很大程度上依赖于对应匹配的质量，而对于没有丰富纹理的物体，匹配对应关系的困难往往会导致重建结果中出现严重的伪影和缺失部分。或者，体积重建方法通过从多视图图像中估计体素网格中的占用率和颜色并评估每个体素的颜色一致性来规避显式对应匹配的困难。由于可实现的体素分辨率有限，这些方法无法实现高精度。</p>
<p>Neural Implicit Representation. 一些方法通过引入归纳偏差来加强深度学习框架中的 3D 理解。这些归纳偏差可以是显式表示，例如体素网格 [13, 5, 47]、点云 [7, 25, 19]、网格 [44, 46, 14] 和隐式表示。神经网络编码的隐式表示最近引起了广泛关注，因为它是连续的并且可以实现高空间分辨率。该表示已成功应用于形状表示 [27, 28, 32, 4, 1, 10, 50, 33]、新视图合成 [40, 24, 15, 29, 22, 34, 35, 43, 39] 和多视图 3D 重建 [49, 30, 17, 12, 23]。<br>我们的工作主要集中于通过经典的渲染技术从二维图像中学习隐式神经表征，该表征编码了三维空间中的几何和外观。受限于这个范围，相关工作可以根据所使用的渲染技术大致分为基于表面渲染的方法和基于体积渲染的方法。基于表面渲染的方法 [30, 17, 49, 23] 假设射线的颜色仅依赖于射线与场景几何图形相交的颜色，这使得梯度仅反向传播到相交点附近的局部区域。因此，这类方法难以重建具有严重自遮挡和突然深度变化的复杂物体。此外，它们通常需要对象蒙版作为监督。相反，我们的方法在这种具有挑战性的情况下表现良好，而不需要蒙版。<br>基于体积渲染的方法，例如 NeRF[29]，通过对每条射线上采样点的颜色进行 α 合成来渲染图像。如介绍中所述，它可以处理突然的深度变化并合成高质量的图像。然而，从学习到的隐式场中提取高保真表面非常困难，因为基于密度的场景表示对其水平集缺乏足够的约束。相反，我们的方法结合了基于表面绘制和基于体积绘制方法的优点，通过将场景空间约束为有符号距离函数，但应用体积绘制来训练这种具有鲁棒性的表示。同时期的工作 UNISURF [31] 也通过体积绘制学习隐式表面。它通过在优化过程中缩小体积绘制的样本区域来提高重建质量。我们的方法与 UNISURF 的不同之处在于，UNISURF 用占用值表示表面，而我们的方法用 SDF 表示场景，因此可以自然地将表面提取为其零级集，从而获得比 UNISURF 更好的重建精度，这将在后面的实验部分看到。</p>
</blockquote>
<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><blockquote>
<p>给定一组 3D 对象的 posed image $\left\lbrace\mathcal{I}_k\right\rbrace$，我们的目标是重建其表面 $\mathcal{S}$。表面由神经隐式 SDF 的 zero-level set 表示。为了学习 the weights of the neural network，我们开发了一种新颖的 volume rendering method 来渲染隐式 SDF 中的图像，并最小化渲染图像与输入图像之间的差异。这种体积渲染方法可确保在 NeuS 中进行稳健优化，以重建复杂结构的对象。</p>
</blockquote>
<h4 id="Rendering-Procedure"><a href="#Rendering-Procedure" class="headerlink" title="Rendering Procedure"></a>Rendering Procedure</h4><blockquote>
<p><strong>Scene Representation.</strong> 使用 NeuS，要重建的场景对象由两个函数表示：$f: \mathbb{R}^3 \rightarrow \mathbb{R}$，将空间位置 $\mathbf{x} \in \mathbb{R}^3$ 映射到其与对象的有符号距离，以及 $c: \mathbb{R}^3 \times \mathbb{S}^2 \rightarrow \mathbb{R}^3$，对与点 $\mathbf{x} \in \mathbb{R}^3$ 和 viewing direction 观看方向 $\mathbf{v} \in \mathbb{S}^2$ 相关的颜色进行编码。这两个函数均由多层感知器 (MLP) 编码。对象的表面 $\mathcal{S}$ 由其 SDF 的 zero-level set 表示，即：</p>
<p>$$<br>\mathcal{S}&#x3D;\left\lbrace\mathbf{x} \in \mathbb{R}^3 \mid f(\mathbf{x})&#x3D;0\right\rbrace<br>$$<br>为了使用体渲染方法来训练SDF网络，作者首先引入了一个概率密度函数 $\phi_s(f(\mathbf{x}))$, 称为 $S$-density, 其中 $f(\mathbf{x}), \mathbf{x} \in \mathbb{R}^3$，是 SDF，$\phi_s(x)&#x3D;s e^{-s x} &#x2F;\left(1+e^{-s x}\right)^2$，通常称为 logistic density distribution，是 Sigmoid 函数 $\Phi_s(x)&#x3D;\left(1+e^{-s x}\right)^{-1}$ 的导数，即 $\phi_s(x)&#x3D;\Phi_s^{\prime}(x)$。原则上，$\phi_s(x)$ 可以是任何以 0 为中心的单峰（即钟形）密度分布；这里我们选择逻辑密度分布是因为其计算方便。注意，$\phi_s(x)$  的标准差由 $1 &#x2F; s$ 给出，它也是一个可训练参数，也就是说，随着网络训练收敛，$1 &#x2F; s$ 趋近于零。</p>
<p>直观地看，NeuS 的主要思想是，借助 S-density field $\phi_s(f(\mathbf{x}))$，使用体积渲染来训练 SDF 网络，仅使用 2D 输入图像作为监督。在基于此监督成功最小化损失函数后，网络编码的 SDF 的 zero-level set 有望表示准确重建的表面 $\mathcal{S}$，其诱导的 S-density $\phi_s(f(\mathbf{x}))$ 在表面附近呈现显著的高值。</p>
<p><strong>Rendering.</strong> 为了学习神经 SDF 和 color field 的参数，我们建议使用体积渲染方案来渲染所提出的 SDF 表示中的图像。给定一个像素，我们将从该像素发出的射线表示为 $\lbrace\mathbf{p}(t)&#x3D;\mathbf{o}+t \mathbf{v} \mid t \geq 0\rbrace$，其中 $\mathbf{o}$ 是相机的中心，$\mathbf{v}$ 是射线的单位方向向量。我们通过以下方式累积沿射线的颜色：</p>
<p>$$C(\mathbf{o}, \mathbf{v})&#x3D;\int_0^{+\infty} w(t) c(\mathbf{p}(t), \mathbf{v}) \mathrm{d} t$$</p>
<p>其中 $C(\mathbf{o}, \mathbf{v})$ 是该像素的输出颜色，$w(t)$ 是点 $\mathbf{p}(t)$ 的权重，$c(\mathbf{p}(t), \mathbf{v})$ 是沿视线方向 $\mathbf{v}$ 的点 $\mathbf{p}$ 处的颜色。</p>
<p><strong>Requirements on weight function.</strong> 从二维图像中学习准确的 SDF 表示的关键是在输出颜色和 SDF 之间建立适当的联系，即根据场景的 SDF $f$ 得出射线上适当的权重函数 $w(t)$。下面，我们列出了对权重函数 $w(t)$ 的要求。</p>
<ul>
<li><ol>
<li><strong>Unbiased.</strong> 给定相机射线 $\mathbf{p}(t), w(t)$ 在表面交点 $\mathbf{p}(t^*)$ 处达到局部最大值，即 $f(\mathbf{p}(t^*))&#x3D;0$，即点 $\mathbf{p}(t^*)$ 位于 $\operatorname{SDF}(\mathbf{x})$ 的 zero-level set 上。</li>
</ol>
</li>
<li><ol start="2">
<li><strong>Occlusion-aware.</strong> 给定任意两个深度值 $t_0$ 和 $t_1$，满足 $f\left(t_0\right)&#x3D;f\left(t_1\right), w\left(t_0\right)&gt;0$、$w\left(t_1\right)&gt;0$ 和 $t_0&lt;t_1$，则有 $w\left(t_0\right)&gt;w\left(t_1\right)$。也就是说，当两个点具有相同的 SDF 值（因此具有相同的 SDF 诱导的 S-density value）时，靠近视点的点对最终输出颜色的贡献应该比另一个点更大。</li>
</ol>
</li>
</ul>
<p>无偏权重函数 $w(t)$ 保证相机光线与 SDF 零级集的交点对像素颜色贡献最大。遮挡感知属性确保当光线连续穿过多个表面时，渲染过程将正确使用最靠近相机的表面颜色来计算输出颜色。</p>
<p>接下来，我们将首先介绍一种定义权重函数 $w(t)$ 的简单方法，即直接使用体积渲染的标准管道，并解释为什么它不适合重建，然后再介绍我们对 $w(t)$ 的新构造。</p>
<p><strong>Naive solution.</strong> 为了使权重函数具有遮挡感知能力，一个自然的解决方案是基于标准体积渲染公式 [29]，该公式通过以下方式定义权重函数：</p>
<p>$$w(t)&#x3D;T(t) \sigma(t)$$</p>
<p>其中，$\sigma(t)$ 是经典体积绘制中所谓的体积密度，而 $T(t)&#x3D;$ $\exp (-\int_0^t \sigma(u) \mathrm{d} u)$ 表示沿射线的累积透射率。为采用标准体积密度公式 [29]，这里将 $\sigma(t)$ 设置为等于 S-density value，即 $\sigma(t)&#x3D;\phi_s(f(\mathbf{p}(t)))$，权重函数 $w(t)$ 由公式 3 计算。虽然得到的权重函数具有遮挡感知能力，但它存在偏差，因为它会在重建表面中引入固有误差。如图 2 (a) 所示，权重函数 $w(t)$ 在射线到达表面点 $\mathbf{p}(t^*)$ 之前的某点达到局部最大值，满足 $f(\mathbf{p}(t^*))&#x3D;0$。这一事实将在补充材料中得到证明。</p>
<p><strong>Our solution.</strong> 为了介绍我们的解决方案，我们首先介绍一种构建无偏权重函数的直接方法，该方法直接使用归一化的 S-density 作为权重:</p>
<p>$$w(t)&#x3D;\frac{\phi_s(f(\mathbf{p}(t)))}{\int_0^{+\infty} \phi_s(f(\mathbf{p}(u))) \mathrm{d} u}$$</p>
<p>这种权重函数的构造是无偏的，但不考虑遮挡。例如，如果射线穿透两个表面，SDF 函数 $f$ 在射线上将有两个零点，这会导致权重函数 $w(t)$ 上有两个峰值，并且得到的权重函数将在不考虑遮挡的情况下均匀混合两个表面的颜色。</p>
<p>为此，现在我们将基于上述简单的构造，在 SDF 的一阶近似中设计既具有遮挡感知又无偏的权重函数 $w(t)$。为了确保权重函数 $w(t)$ 具有遮挡感知特性，我们仍将遵循体积渲染的基本框架，如公式 3。然而，与上述简单解决方案中的常规处理不同，我们以一种新的方式从 S-density 定义函数 $w(t)$。我们首先定义一个不透明密度函数 $\rho(t)$，它是标准体积渲染中体积密度 $\sigma$ 的对应项。然后我们通过以下方式计算新的权重函数 $w(t)$:</p>
<p>$$w(t)&#x3D;T(t) \rho(t),\quad \text { where } T(t)&#x3D;\exp (-\int_0^t \rho(u) \mathrm{d} u)$$</p>
<p><strong>How we derive opaque density $\rho$.</strong> 我们首先考虑一个简单的理想情况，其中只有一个表面交点，并且该表面只是一个无限接近相机的平面。由于在此假设下，公式 4 确实满足上述要求，因此我们使用体积渲染的框架推导出与公式 4 的权重定义相对应的底层不透明密度 ρ。然后，我们将此不透明密度推广到多个表面相交的一般情况。</p>
<p>具体而言，在单个平面相交的简单情况下，很容易看出有符号距离函数 $f(\mathbf{p}(t))$ 为 $-|\cos (\theta)| \cdot(t-t^*)$，其中 $f(\mathbf{p}(t^*))&#x3D;0$，$\theta$ 是视线方向 $\mathbf{v}$ 与外表面法向量 $\mathbf{n}$ 之间的角度。由于假设表面为平面，$|\cos (\theta)|$ 为常数。从公式 4 可知:</p>
<p>$$<br>\begin{aligned}<br>w(t) &amp; &#x3D;\lim _{t^* \rightarrow+\infty} \frac{\phi_s(f(\mathbf{p}(t)))}{\int_0^{+\infty} \phi_s(f(\mathbf{p}(u))) \mathrm{d} u} \<br>&amp; &#x3D;\lim _{t^* \rightarrow+\infty} \frac{\phi_s(f(\mathbf{p}(t)))}{\int_0^{+\infty} \phi_s\left(-|\cos (\theta)|\left(u-t^<em>\right)\right) \mathrm{d} u} \<br>&amp; &#x3D;\lim _{t^</em> \rightarrow+\infty} \frac{\phi_s(f(\mathbf{p}(t)))}{\int_{-t^*}^{+\infty} \phi_s\left(-|\cos (\theta)| u^<em>\right) \mathrm{d} u^</em>} \<br>&amp; &#x3D;\lim <em>{t^* \rightarrow+\infty} \frac{\phi_s(f(\mathbf{p}(t)))}{|\cos (\theta)|^{-1} \int</em>{-|\cos (\theta)| t^*}^{+\infty} \phi_s(\hat{u}) \mathrm{d} \hat{u}} \<br>&amp; &#x3D;|\cos (\theta)| \phi_s(f(\mathbf{p}(t))) .<br>\end{aligned}<br>$$</p>
<p>回想一下，体积渲染框架内的权重函数由 $w(t)&#x3D;T(t) \rho(t)$ 给出，其中 $T(t)&#x3D;\exp \left(-\int_0^t \rho(u) \mathrm{d} u\right)$ 表示<em>累积透射率</em>。因此，为了 derive $\rho(t)$，我们有:<br>$$T(t) \rho(t)&#x3D;|\cos (\theta)| \phi_s(f(\mathbf{p}(t)))$$<br>由于 $T(t)&#x3D;\exp \left(-\int_0^t \rho(u) \mathrm{d} u\right)$，因此很容易验证 $T(t) \rho(t)&#x3D;-\frac{\mathrm{d} T}{\mathrm{<del>d} t}(t)$。此外，请注意 $|\cos (\theta)| \phi_s(f(\mathbf{p}(t)))&#x3D;-\frac{\mathrm{d} \Phi_s}{\mathrm{</del>d} t}(f(\mathbf{p}(t)))$。由此可知 $\frac{\mathrm{d} T}{\mathrm{<del>d} t}(t)&#x3D;\frac{\mathrm{d} \Phi_s}{\mathrm{</del>d} t}(f(\mathbf{p}(t)))$。对该等式两边求积分可得出：</p>
</blockquote>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><blockquote>
<p>我们提出了 NeuS，这是一种新的多视图表面​​重建方法，它将 3D 表面表示为神经 SDF，并开发了一种用于训练隐式 SDF 表示的新体积渲染方法。NeuS 可产生高质量的重建，并成功重建具有严重遮挡和复杂结构的物体。它在质量和数量上都优于最先进的技术。我们方法的一个局限性是，尽管我们的方法并不严重依赖纹理特征的对应匹配，但对于无纹理物体，性能仍然会下降（我们在补充材料中展示了失败案例）。此外，NeuS 只有一个尺度参数 s，用于对所有空间位置的概率分布的标准偏差进行建模。因此，一个有趣的未来研究课题是根据不同的局部几何特征对不同空间位置的概率进行建模，同时优化场景表示。负面社会影响：与许多其他基于学习的作品一样，我们的方法需要大量的计算资源进行网络训练，这可能是全球气候变化的一个问题。</p>
</blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/614008188">NeRF系列工作个人总结 - 氵景页的文章 - 知乎</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/flow_specter/article/details/126222914">论文笔记：NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction</a></p>
<p><a target="_blank" rel="noopener" href="https://longtimenohack.com/posts/paper_reading/2021_wang_neus/">Jianfei Guo</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-06-30T17:56:38.000Z" title="2024-06-30T17:56:38.000Z">2024-07-01</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-07-02T16:53:24.752Z" title="2024-07-02T16:53:24.752Z">2024-07-03</time></span><span class="level-item"><a class="link-muted" href="/categories/Contest-Notes/">Contest Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/epic-institute-of-technology-round-summer-2024-div-1-div-2/">EPIC Institute of Technology Round Summer 2024 (Div. 1 + Div. 2)</a></p><div class="content"><p><a target="_blank" rel="noopener" href="https://codeforces.com/contest/1987">比赛链接</a></p>
<table>
<thead>
<tr>
<th>Problems</th>
<th>AC</th>
</tr>
</thead>
<tbody><tr>
<td>A. Upload More RAM</td>
<td>○</td>
</tr>
<tr>
<td>B. K-Sort</td>
<td>○</td>
</tr>
<tr>
<td>C. Basil’s Garden</td>
<td>○</td>
</tr>
<tr>
<td>D. World is Mine</td>
<td>○</td>
</tr>
<tr>
<td>E. Wonderful Tree!</td>
<td>○</td>
</tr>
<tr>
<td>F1. Interesting Problem (Easy Version)</td>
<td>⊕</td>
</tr>
<tr>
<td>F2. Interesting Problem (Hard Version)</td>
<td>⊕</td>
</tr>
<tr>
<td>G1. Spinning Round (Easy Version)</td>
<td></td>
</tr>
<tr>
<td>G2. Spinning Round (Hard Version)</td>
<td></td>
</tr>
<tr>
<td>H. Fumo Temple</td>
<td></td>
</tr>
</tbody></table></div><a class="article-more button is-small is-size-7" href="/epic-institute-of-technology-round-summer-2024-div-1-div-2/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-06-25T19:56:01.000Z" title="2024-06-25T19:56:01.000Z">2024-06-26</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-06-27T11:54:52.986Z" title="2024-06-27T11:54:52.986Z">2024-06-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Contest-Notes/">Contest Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/codeforces-round-955-div-2-with-prizes-from-near/">Codeforces Round 955 (Div. 2, with prizes from NEAR!)</a></p><div class="content"><p>重生之我是 Jumping</p>
<p><a target="_blank" rel="noopener" href="https://codeforces.com/contest/1982">比赛链接</a></p>
<table>
<thead>
<tr>
<th>Problems</th>
<th>AC</th>
</tr>
</thead>
<tbody><tr>
<td>A. Soccer</td>
<td>○</td>
</tr>
<tr>
<td>B. Collatz Conjecture</td>
<td>○</td>
</tr>
<tr>
<td>C. Boring Day</td>
<td>○</td>
</tr>
<tr>
<td>D. Beauty of the mountains</td>
<td>○</td>
</tr>
<tr>
<td>E. Number of k-good subarrays</td>
<td>⊕</td>
</tr>
<tr>
<td>F. Sorting Problem Again</td>
<td>⊕</td>
</tr>
</tbody></table></div><a class="article-more button is-small is-size-7" href="/codeforces-round-955-div-2-with-prizes-from-near/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-06-23T17:25:29.000Z" title="2024-06-23T17:25:29.000Z">2024-06-24</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-06-27T07:37:23.273Z" title="2024-06-27T07:37:23.273Z">2024-06-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Contest-Notes/">Contest Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/codeforces-round-954-div-3/">Codeforces Round 954 (Div. 3)</a></p><div class="content"><p>发现自己的小号已经 unrated for div3 了</p>
<p>这什么神笔场，F 不会求割边和点双被卡科技了，G1 G2 赛时想出正解但是以为自己的复杂度是错的就没写。。。</p>
<p><a target="_blank" rel="noopener" href="https://codeforces.com/contest/1986">比赛链接</a></p>
<table>
<thead>
<tr>
<th>Problems</th>
<th>AC</th>
</tr>
</thead>
<tbody><tr>
<td>A. X Axis</td>
<td>○</td>
</tr>
<tr>
<td>B. Matrix Stabilization</td>
<td>○</td>
</tr>
<tr>
<td>C. Update Queries</td>
<td>○</td>
</tr>
<tr>
<td>D. Mathematical Problem</td>
<td>○</td>
</tr>
<tr>
<td>E. Beautiful Array</td>
<td>○</td>
</tr>
<tr>
<td>F. Non-academic Problem</td>
<td>⊕</td>
</tr>
<tr>
<td>G1. Permutation Problem (Simple Version)</td>
<td>⊕</td>
</tr>
<tr>
<td>G2. Permutation Problem (Hard Version)</td>
<td>⊕</td>
</tr>
</tbody></table></div><a class="article-more button is-small is-size-7" href="/codeforces-round-954-div-3/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-06-20T08:34:52.000Z" title="2024-06-20T08:34:52.000Z">2024-06-20</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-06-23T12:22:04.659Z" title="2024-06-23T12:22:04.659Z">2024-06-23</time></span><span class="level-item"><a class="link-muted" href="/categories/Contest-Notes/">Contest Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/vp-2024-icpc-%E6%AD%A6%E6%B1%89%E9%82%80%E8%AF%B7%E8%B5%9B/">VP 2024 ICPC 武汉邀请赛</a></p><div class="content"><p>VP Date 2024&#x2F;5&#x2F;17</p>
<p><a target="_blank" rel="noopener" href="https://codeforces.com/contest/105143">比赛链接</a></p>
<table>
<thead>
<tr>
<th>Problems</th>
<th>AC</th>
</tr>
</thead>
<tbody><tr>
<td>A. Shaking Trees</td>
<td></td>
</tr>
<tr>
<td>B. Countless Me</td>
<td>○</td>
</tr>
<tr>
<td>C. TreeBag and LIS</td>
<td></td>
</tr>
<tr>
<td>D. ICPC</td>
<td>⊕</td>
</tr>
<tr>
<td>E. Boomerang</td>
<td>⊕</td>
</tr>
<tr>
<td>F. Custom-Made Clothes</td>
<td>○</td>
</tr>
<tr>
<td>G. Pack</td>
<td></td>
</tr>
<tr>
<td>H. Wings of Crystals</td>
<td></td>
</tr>
<tr>
<td>I. Cyclic Apple Strings</td>
<td>○</td>
</tr>
<tr>
<td>J. Gensokyo Autobahn</td>
<td></td>
</tr>
<tr>
<td>K. Party Games</td>
<td>○</td>
</tr>
<tr>
<td>L. Magic Fairies</td>
<td></td>
</tr>
<tr>
<td>M. Merge</td>
<td>⊕</td>
</tr>
</tbody></table></div><a class="article-more button is-small is-size-7" href="/vp-2024-icpc-%E6%AD%A6%E6%B1%89%E9%82%80%E8%AF%B7%E8%B5%9B/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-06-17T01:56:05.000Z" title="2024-06-17T01:56:05.000Z">2024-06-17</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-06-17T13:28:15.097Z" title="2024-06-17T13:28:15.097Z">2024-06-17</time></span><span class="level-item"><a class="link-muted" href="/categories/Contest-Notes/">Contest Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/codeforces-round-953-div-2/">Codeforces Round 953 (Div. 2)</a></p><div class="content"><p><a target="_blank" rel="noopener" href="https://codeforces.com/contest/1978">比赛链接</a></p>
<table>
<thead>
<tr>
<th>Problems</th>
<th>AC</th>
</tr>
</thead>
<tbody><tr>
<td>A. Alice and Books</td>
<td>○</td>
</tr>
<tr>
<td>B. New Bakery</td>
<td>○</td>
</tr>
<tr>
<td>C. Manhattan Permutations</td>
<td>○</td>
</tr>
<tr>
<td>D. Elections</td>
<td>○</td>
</tr>
<tr>
<td>E. Computing Machine</td>
<td>⊕</td>
</tr>
<tr>
<td>F. Large Graph</td>
<td>⊕</td>
</tr>
</tbody></table></div><a class="article-more button is-small is-size-7" href="/codeforces-round-953-div-2/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-06-12T02:41:20.000Z" title="2024-06-12T02:41:20.000Z">2024-06-12</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-06-20T06:15:22.147Z" title="2024-06-20T06:15:22.147Z">2024-06-20</time></span><span class="level-item"><a class="link-muted" href="/categories/Contest-Notes/">Contest Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/codeforces-round-952-div-4/">Codeforces Round 952 (Div. 4)</a></p><div class="content"><p>赛后一个题一个题做的</p>
<p><a target="_blank" rel="noopener" href="https://codeforces.com/contest/1985">比赛链接</a></p>
<table>
<thead>
<tr>
<th>Problems</th>
<th>AC</th>
</tr>
</thead>
<tbody><tr>
<td>A. Creating Words</td>
<td>○</td>
</tr>
<tr>
<td>B. Maximum Multiple Sum</td>
<td>○</td>
</tr>
<tr>
<td>C. Good Prefixes</td>
<td>○</td>
</tr>
<tr>
<td>D. Manhattan Circle</td>
<td>○</td>
</tr>
<tr>
<td>E. Secret Box</td>
<td>○</td>
</tr>
<tr>
<td>F. Final Boss</td>
<td>○</td>
</tr>
<tr>
<td>G. D-Function</td>
<td>○</td>
</tr>
<tr>
<td>H1. Maximize the Largest Component (Easy Version)</td>
<td>○</td>
</tr>
<tr>
<td>H2. Maximize the Largest Component (Hard Version)</td>
<td>○</td>
</tr>
</tbody></table></div><a class="article-more button is-small is-size-7" href="/codeforces-round-952-div-4/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-06-11T02:37:26.000Z" title="2024-06-11T02:37:26.000Z">2024-06-11</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-06-30T12:57:01.884Z" title="2024-06-30T12:57:01.884Z">2024-06-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Research-Notes/">Research Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/3d-gaussian-splatting/">3D Gaussian Splatting</a></p><div class="content"><p>研究重点：indoor</p></div><a class="article-more button is-small is-size-7" href="/3d-gaussian-splatting/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-06-10T06:24:30.000Z" title="2024-06-10T06:24:30.000Z">2024-06-10</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-06-25T18:12:48.535Z" title="2024-06-25T18:12:48.535Z">2024-06-26</time></span><span class="level-item"><a class="link-muted" href="/categories/Contest-Notes/">Contest Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/codeforces-global-round-26/">Codeforces Global Round 26</a></p><div class="content"><p><a target="_blank" rel="noopener" href="https://codeforces.com/contest/1984">比赛链接</a></p>
<table>
<thead>
<tr>
<th>Problems</th>
<th>AC</th>
</tr>
</thead>
<tbody><tr>
<td>A. Strange Splitting</td>
<td>○</td>
</tr>
<tr>
<td>B. Large Addition</td>
<td>○</td>
</tr>
<tr>
<td>C1. Magnitude (Easy Version)</td>
<td>○</td>
</tr>
<tr>
<td>C2. Magnitude (Hard Version)</td>
<td>○</td>
</tr>
<tr>
<td>D. ‘’a’’ String Problem</td>
<td>○</td>
</tr>
<tr>
<td>E. Shuffle</td>
<td></td>
</tr>
<tr>
<td>F. Reconstruction</td>
<td></td>
</tr>
</tbody></table></div><a class="article-more button is-small is-size-7" href="/codeforces-global-round-26/#more">Read more</a></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/page/0/">Previous</a></div><div class="pagination-next"><a href="/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/7/">7</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://www.gravatar.com/avatar/31211fa60563a6ba75694c331094f574?s=128" alt="TosakaUCW"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">TosakaUCW</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Hangzhou, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">66</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">15</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/TosakaUCW" target="_blank" rel="me noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/TosakaUCW"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="QQ" href="tencent://message/?uin=2736275924&amp;Site=&amp;Menu=yes"><i class="fab fa-qq"></i></a></div></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-07-04T08:56:39.000Z">2024-07-04</time></p><p class="title"><a href="/360-gs-paper-%E7%BB%86%E8%AF%BB/">360-GS Paper 细读</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-07-03T16:00:53.000Z">2024-07-04</time></p><p class="title"><a href="/neus-paper-%E7%BB%86%E8%AF%BB/">NeuS Paper 细读</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-06-30T17:56:38.000Z">2024-07-01</time></p><p class="title"><a href="/epic-institute-of-technology-round-summer-2024-div-1-div-2/">EPIC Institute of Technology Round Summer 2024 (Div. 1 + Div. 2)</a></p><p class="categories"><a href="/categories/Contest-Notes/">Contest Notes</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-06-25T19:56:01.000Z">2024-06-26</time></p><p class="title"><a href="/codeforces-round-955-div-2-with-prizes-from-near/">Codeforces Round 955 (Div. 2, with prizes from NEAR!)</a></p><p class="categories"><a href="/categories/Contest-Notes/">Contest Notes</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-06-23T17:25:29.000Z">2024-06-24</time></p><p class="title"><a href="/codeforces-round-954-div-3/">Codeforces Round 954 (Div. 3)</a></p><p class="categories"><a href="/categories/Contest-Notes/">Contest Notes</a></p></div></article></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Contest-Notes/"><span class="level-start"><span class="level-item">Contest Notes</span></span><span class="level-end"><span class="level-item tag">24</span></span></a></li><li><a class="level is-mobile" href="/categories/Lecture-Notes/"><span class="level-start"><span class="level-item">Lecture Notes</span></span><span class="level-end"><span class="level-item tag">32</span></span></a></li><li><a class="level is-mobile" href="/categories/OI-Notes/"><span class="level-start"><span class="level-item">OI Notes</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Research-Notes/"><span class="level-start"><span class="level-item">Research Notes</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tech-Notes/"><span class="level-start"><span class="level-item">Tech Notes</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Travel-Notes/"><span class="level-start"><span class="level-item">Travel Notes</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/3DGS/"><span class="tag">3DGS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/APSY/"><span class="tag">APSY</span><span class="tag">31</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AtCoder/"><span class="tag">AtCoder</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Codeforces/"><span class="tag">Codeforces</span><span class="tag">19</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Icarus/"><span class="tag">Icarus</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PSY2013/"><span class="tag">PSY2013</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PSY2033/"><span class="tag">PSY2033</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PSY2043/"><span class="tag">PSY2043</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/UIC/"><span class="tag">UIC</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VP/"><span class="tag">VP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/XCPC/"><span class="tag">XCPC</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/"><span class="tag">蓝桥杯</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="TosakaUCW" height="28"></a><p class="is-size-7"><span>&copy; 2024 TosakaUCW</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2024</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/TosakaUCW"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>